{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df =pd.read_json('przepisy.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.ingredient_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'przepisy.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-028b41ed0fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'przepisy.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrecipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'przepisy.json'"
     ]
    }
   ],
   "source": [
    "with open('przepisy.json', encoding='utf8') as json_file:\n",
    "    recipes = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = []\n",
    "for recipe in recipes:\n",
    "    for ingredient in recipe['ingredient_list']:\n",
    "        ingredients.append([ recipe['url'], ingredient['ingredient_name'], \n",
    "                            ingredient['ingredient_amount'],\n",
    "                            ingredient['ingredient_unit']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ingredients, columns=[\"URL\", \"nazwa\", \"ilosc\", \"jednostka\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text distance\n",
    "\n",
    "import textdistance as td\n",
    "\n",
    "# %pip install textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def FindSimilarIngrs(ingr, tol = .0 ):\n",
    "\n",
    "#     similarities = []\n",
    "\n",
    "#     for name in df['nazwa']: \n",
    "#         score = td.hamming.normalized_similarity(name,ingr)\n",
    "#         if( score > tolerance ):\n",
    "#             kro = (name, score)\n",
    "#             if(kro not in similarities):\n",
    "#                 similarities.append(kro)\n",
    "#                 print( kro )\n",
    "# FindSimilarIngrs('pomidor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tolerance = 0.7\n",
    "\n",
    "# similarities = []\n",
    "\n",
    "# for name in df['nazwa']: \n",
    "#     for second_name in df['nazwa']:\n",
    "#         score = td.hamming.normalized_similarity(name,second_name)\n",
    "#         if(score < 1 and score> tolerance):\n",
    "#             kro = (name, second_name, score)\n",
    "#             if(kro not in similarities):\n",
    "#                 similarities.append(kro)\n",
    "#                 print( kro )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = df['nazwa'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "def find_similar(ingredient):\n",
    "    for name in unique_names:\n",
    "        match = difflib.SequenceMatcher(None, ingredient, name).ratio()\n",
    "        if match > 0.6:\n",
    "            print(name, match)\n",
    "\n",
    "            find_similar('szalotka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = \"(testing)\"\n",
    "# d = ['(',',',\")\",'']\n",
    "# #test.replace('(','')\n",
    "\n",
    "# for s in d:\n",
    "#     test = test.replace(s,'')\n",
    "    \n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = []\n",
    "# for name in unique_names:\n",
    "#     names=names+name.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = ['(',',',\")\"]\n",
    "# for s in d:\n",
    "#     #test = test.replace(s,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in setofnames:\n",
    "#     item = item.replace('(','')\n",
    "# # setofnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clear(names):\n",
    "    n=[]\n",
    "    for name in names:\n",
    "        a=re.sub('[^a-ząćęółżźśń ]+', '', name)\n",
    "        n.append(a)\n",
    "    return n\n",
    "names = Clear(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni =pd.DataFrame(columns=['name','count'])\n",
    "setofnames = set(names)\n",
    "for i,name in enumerate(setofnames):\n",
    "    a = names.count(name)\n",
    "    df_uni.loc[i] = [name, a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uni.sort_values('count', ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.sub('[^A-Za-z0-9]+', '', mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = [\"\", \"z\", \"w\", \"lub\", \"do\", \"i\", \"bez\", \"-\", \"świeży\", \"np.\", \"na\", \"g\", \"mała\", \"np\",\n",
    "#              \"suszone\", \"puszki\", \"pokrojona\", \"czerwona\", \"świeże\", \"zielona\", \"kilka\", \"kostkę\",\n",
    "#              \"pokrojone\", \"biała\", \"ze\", \"żółty\", \"mały\", \"świeża\", \"pęczek\", \"dekoracja\",\n",
    "#              \"duże\", \"mrożone\", \"knorr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
